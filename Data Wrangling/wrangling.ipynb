{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA WRANGLING\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I have iterated through the folders containing all the students csv's.\n",
    "\n",
    "In my iteration, I have enforced a couple rules to ensure each file is appended successfully, these are:\n",
    "* __`pd.read_csv(path, dtype=object)`__ - Many of the columns I am appending have mixed datatypes so I am setting all the columns to string to ensure there are no errors and will perform column operations to clean these in a later step.\n",
    "* __`str.lower, str.strip`__ - I have used these two string operations in an attempt to minimize column name differences. This results in the whole string lowercased with all whitespaces removed. Even with these two operations, this revealed an excessive amount of core columns columns specified in the instructions worded differently.\n",
    "* __`dropna(how='all')`__ - When pandas reads in a csv, if there is a formatted table extending beyond the data entries, this is read as null rows by default in the dataframe. In one particular case there was over 1m rows (`22351482.csv`). This method eliminates these cases.\n",
    "\n",
    "Finally, I also assigned 3 columns to each csv which will help in handling, producing general count statistics and identifying files, these are: __`file_idx`__ - a unique file ID, __`file_name`__ - the name of the file, __`folder_name`__ - the folder this column is located in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12953 entries, 0 to 139\n",
      "Columns: 162 entries, date to undergraduate driver\n",
      "dtypes: int64(1), object(161)\n",
      "memory usage: 16.1+ MB\n",
      "None \n",
      "\n",
      "Index(['date', 'time', 'direction', 'type', 'occupancy', 'color',\n",
      "       'public/private', 'file_idx', 'file_name', 'folder_name',\n",
      "       ...\n",
      "       'public transport', 'car company/bus no', 'busno',\n",
      "       'transport type (public/private)', 'pedestrian count',\n",
      "       'type of transportation', 'bus type', 'temperature (c)',\n",
      "       'cumulative frequency', 'undergraduate driver'],\n",
      "      dtype='object', length=162)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>direction</th>\n",
       "      <th>type</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>color</th>\n",
       "      <th>public/private</th>\n",
       "      <th>file_idx</th>\n",
       "      <th>file_name</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>...</th>\n",
       "      <th>public transport</th>\n",
       "      <th>car company/bus no</th>\n",
       "      <th>busno</th>\n",
       "      <th>transport type (public/private)</th>\n",
       "      <th>pedestrian count</th>\n",
       "      <th>type of transportation</th>\n",
       "      <th>bus type</th>\n",
       "      <th>temperature (c)</th>\n",
       "      <th>cumulative frequency</th>\n",
       "      <th>undergraduate driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23/10/2023</td>\n",
       "      <td>10.30am</td>\n",
       "      <td>out</td>\n",
       "      <td>car</td>\n",
       "      <td>0.2</td>\n",
       "      <td>grey</td>\n",
       "      <td>private</td>\n",
       "      <td>1</td>\n",
       "      <td>22792703.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/10/2023</td>\n",
       "      <td>10.30am</td>\n",
       "      <td>out</td>\n",
       "      <td>car</td>\n",
       "      <td>0.2</td>\n",
       "      <td>other</td>\n",
       "      <td>private</td>\n",
       "      <td>1</td>\n",
       "      <td>22792703.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23/10/2023</td>\n",
       "      <td>10.30am</td>\n",
       "      <td>out</td>\n",
       "      <td>car</td>\n",
       "      <td>0.2</td>\n",
       "      <td>grey</td>\n",
       "      <td>private</td>\n",
       "      <td>1</td>\n",
       "      <td>22792703.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23/10/2023</td>\n",
       "      <td>10.30am</td>\n",
       "      <td>out</td>\n",
       "      <td>van</td>\n",
       "      <td>0.5</td>\n",
       "      <td>white</td>\n",
       "      <td>public</td>\n",
       "      <td>1</td>\n",
       "      <td>22792703.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/10/2023</td>\n",
       "      <td>10.30am</td>\n",
       "      <td>out</td>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "      <td>1</td>\n",
       "      <td>22792703.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time direction type occupancy  color public/private  \\\n",
       "0  23/10/2023  10.30am       out  car       0.2   grey        private   \n",
       "1  23/10/2023  10.30am       out  car       0.2  other        private   \n",
       "2  23/10/2023  10.30am       out  car       0.2   grey        private   \n",
       "3  23/10/2023  10.30am       out  van       0.5  white         public   \n",
       "4  23/10/2023  10.30am       out  van         1    NaN         public   \n",
       "\n",
       "   file_idx     file_name    folder_name  ... public transport  \\\n",
       "0         1  22792703.csv  csv_data_2023  ...              NaN   \n",
       "1         1  22792703.csv  csv_data_2023  ...              NaN   \n",
       "2         1  22792703.csv  csv_data_2023  ...              NaN   \n",
       "3         1  22792703.csv  csv_data_2023  ...              NaN   \n",
       "4         1  22792703.csv  csv_data_2023  ...              NaN   \n",
       "\n",
       "  car company/bus no busno transport type (public/private) pedestrian count  \\\n",
       "0                NaN   NaN                             NaN              NaN   \n",
       "1                NaN   NaN                             NaN              NaN   \n",
       "2                NaN   NaN                             NaN              NaN   \n",
       "3                NaN   NaN                             NaN              NaN   \n",
       "4                NaN   NaN                             NaN              NaN   \n",
       "\n",
       "  type of transportation bus type temperature (c) cumulative frequency  \\\n",
       "0                    NaN      NaN             NaN                  NaN   \n",
       "1                    NaN      NaN             NaN                  NaN   \n",
       "2                    NaN      NaN             NaN                  NaN   \n",
       "3                    NaN      NaN             NaN                  NaN   \n",
       "4                    NaN      NaN             NaN                  NaN   \n",
       "\n",
       "  undergraduate driver  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended_raw = pd.DataFrame()\n",
    "\n",
    "ticker=0\n",
    "for folder in os.listdir(r'DATA'):\n",
    "    if folder.startswith('csv'):\n",
    "        year_files = os.listdir(r'DATA/' + folder)\n",
    "        for file in year_files:\n",
    "            if file.endswith('.csv'):\n",
    "\n",
    "                ticker += 1\n",
    "\n",
    "                tmp_file = pd.read_csv(r'DATA/' + folder + '/' + file, dtype=object)\n",
    "                tmp_file.dropna(how='all', inplace=True)\n",
    "\n",
    "                tmp_file.columns = map(str.lower, tmp_file.columns)\n",
    "                tmp_file.columns = map(str.strip, tmp_file.columns)\n",
    "\n",
    "                tmp_file['file_idx'] = ticker\n",
    "                tmp_file['file_name'] = file\n",
    "                tmp_file['folder_name'] = folder\n",
    "                \n",
    "                appended_raw = appended_raw.append(tmp_file)\n",
    "\n",
    "print(appended_raw.info(), '\\n')\n",
    "print(appended_raw.columns)\n",
    "appended_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this cell is to export an excel with all the raw column names not included in the 5 standard columns required in the spec.\n",
    "\n",
    "This excel will contain 3 columns: \n",
    "* __`raw_column`__ - the column not in our standard columns list. Most of the time this will be the unique columns the group chose to include for their research question. In some cases groups have not followed the specification instructions in naming these columns so these will also have to be identified.\n",
    "* __`file`__ - the name of the file\n",
    "* __`folder`__ - the folder the column is located in\n",
    "* __`sample_values`__ - 5 sample values of the column to allow us to tag it to an appropriate column\n",
    "\n",
    "This will expedite the process of searching and uderstanding the columns. Once I have my helper search file, I will create a lookup file / dimension table with the unique column names which will manually map onto a second column 'column_mod' used to rename all the columns I have concluded are referring to the same observation to the same column name. This lookup file will then be used in the iteration which joins all the csv's to ensure these observations are appended in the same column. After this step is completed I will then be able to apply rules to the column to set values to a predefined format which can be used in my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_column</th>\n",
       "      <th>sample_values</th>\n",
       "      <th>column_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>22792702.csv</td>\n",
       "      <td>additionaldata1</td>\n",
       "      <td>[No, No, No, No, No]</td>\n",
       "      <td>unwanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>22792780.csv</td>\n",
       "      <td>additionaldata2</td>\n",
       "      <td>[ null,  null,  null,  null,  null]</td>\n",
       "      <td>unwanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>22351436.csv</td>\n",
       "      <td>additionaldata2</td>\n",
       "      <td>[ null,  null,  null,  null,  null]</td>\n",
       "      <td>unwanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>22792737.csv</td>\n",
       "      <td>age group</td>\n",
       "      <td>[30 - 34, under 30, 30 - 34, 30 - 34, above 45]</td>\n",
       "      <td>unwanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>22792798.csv</td>\n",
       "      <td>age group</td>\n",
       "      <td>[30 - 45, 30 - 45, 30 - 45, 30 - 45, 30 - 45]</td>\n",
       "      <td>unwanted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     folder_name     file_name       raw_column  \\\n",
       "0  csv_data_2023  22792702.csv  additionaldata1   \n",
       "1  csv_data_2023  22792780.csv  additionaldata2   \n",
       "2  csv_data_2022  22351436.csv  additionaldata2   \n",
       "3  csv_data_2023  22792737.csv        age group   \n",
       "4  csv_data_2023  22792798.csv        age group   \n",
       "\n",
       "                                     sample_values column_mod  \n",
       "0                             [No, No, No, No, No]   unwanted  \n",
       "1              [ null,  null,  null,  null,  null]   unwanted  \n",
       "2              [ null,  null,  null,  null,  null]   unwanted  \n",
       "3  [30 - 34, under 30, 30 - 34, 30 - 34, above 45]   unwanted  \n",
       "4    [30 - 45, 30 - 45, 30 - 45, 30 - 45, 30 - 45]   unwanted  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_map = appended_raw.copy()\n",
    "column_map = column_map[column_map.columns[~column_map.columns.isin(['date', 'time', 'direction', 'type', 'occupancy', 'file_idx'])]]\n",
    "column_map = pd.melt(column_map, id_vars=['folder_name', 'file_name'], var_name='raw_column', ignore_index=1).dropna(subset=['value'])\n",
    "column_map = column_map.groupby(['folder_name', 'file_name', 'raw_column'], as_index=False).agg({'value':lambda x: list(x)})\n",
    "column_map = column_map.reset_index(drop=True).rename(columns={'value': 'sample_values'})\n",
    "column_map['sample_values'] = column_map['sample_values'].apply(lambda x: x[:5])\n",
    "\n",
    "# Reference file for every occurence of the column name. This excel will expediate understanding what the column is referring to so I can assign a column name to it in the next step. \n",
    "# 'column_mod' is filled out manually and is the lookup value raw_column should be renamed to.\n",
    "column_map = column_map.sort_values(by='raw_column')\n",
    "lookup = pd.read_excel(r'DATA/unique_raw_columns.xlsx')\n",
    "column_map = pd.merge(column_map, lookup, how='inner', on='raw_column')\n",
    "column_map.to_excel(r'DATA/column_reference.xlsx', index=False)\n",
    "\n",
    "column_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially the point where the wrangling begins. \n",
    "\n",
    "In this step I am using the lookup file I created `column_reference.xlsx` to change the names of the columns I want to keep which have been recorded by different groups but are a reference to the same observation. In the lookup file I have also identified columns which were supposed to be core columns defined in the spec release and corrected them.\n",
    "\n",
    "Following the same iterative logic appending the raw datasets with some additional rules in place, I am creating the core columns dataframe plus a selection of useful additional columns I have identified. \n",
    "\n",
    "The process together with the new parts is as follows: \n",
    "* __`pd.read_csv(path, dtype=object)`__ - Many of the columns I am appending have mixed datatypes so I am setting all the columns to string to ensure there are no errors and will perform column operations to clean these in a later step.\n",
    "* __`str.lower, str.strip`__ - I have used these two string operations in an attempt to minimize column name differences. This results in the whole string lowercased with all whitespaces removed. Even with these two operations, this revealed an excessive amount of core columns columns specified in the instructions worded differently.\n",
    "* __`dropna(how='all')`__ - When pandas reads in a csv, if there is a formatted table extending beyond the data entries, this is read as null rows by default in the dataframe. In one particular case there was over 1m rows (`22351482.csv`). This method eliminates these cases.\n",
    "* __`file['date/time'].ffill()`__ - Some groups filled out only the time which an interval changes. For these cases I implemented a forward fill to complete the null rows.\n",
    "* __`np.select()`__ - Dataframe column lookup accessor based on conditions of other columns, returns `column_mod` which is my manual column mapping.\n",
    "* __`'unwanted' columns`__ -  The the process ensures only the useful columns I have chosen are kept by iterating through the temporary file's columns, renaming useful columns and checking whether the lookup returns 'unwanted' in which case it drops the current column.\n",
    "* __`try/except - incompatible file formats`__ -  I have added a try except to catch files which even after renaming fail the append. These are csv's which have not been unpivoted/melted, and while digital, are still in their physical collection format. They would require excessive processing and are deemed unfit. These files are tracked in the `unfit_files` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_plus_useful_columns = pd.DataFrame()\n",
    "column_lookup = pd.read_excel(r'DATA/column_reference.xlsx')\n",
    "\n",
    "unfit_files = []\n",
    "ticker=0\n",
    "\n",
    "for folder in os.listdir(r'DATA'):\n",
    "    if folder.startswith('csv'):\n",
    "        year_files = os.listdir(r'DATA/' + folder)\n",
    "        for file in year_files:\n",
    "            if file.endswith('.csv'):\n",
    "\n",
    "                ticker += 1\n",
    "                \n",
    "                # I have implemented a try/except in this case to intentionally leave out files which do not match the columns specified. \n",
    "                # These require much more processing (i.e. unpivoting/melting vehicle types from their raw data collection form) and are therefore considered unfit.\n",
    "                try:\n",
    "                    tmp_file = pd.read_csv(r'DATA/' + folder + '/' + file, dtype=object)\n",
    "                    tmp_file.dropna(how='all', inplace=True)\n",
    "\n",
    "                    tmp_file.columns = map(str.lower, tmp_file.columns)\n",
    "                    tmp_file.columns = map(str.strip, tmp_file.columns)\n",
    "\n",
    "                    tmp_file['date'] = tmp_file['date'].ffill()\n",
    "                    tmp_file['time'] = tmp_file['time'].ffill()\n",
    "\n",
    "                    for col_i in tmp_file.columns:\n",
    "                        if col_i not in ['date', 'time', 'direction', 'type', 'occupancy']:\n",
    "                            fetched_col =  np.select(column_lookup['raw_column'] == col_i, column_lookup['column_mod']).item()\n",
    "                            if fetched_col == 'unwanted':\n",
    "                                tmp_file = tmp_file.drop(columns=col_i)\n",
    "                            else:\n",
    "                                tmp_file = tmp_file.rename(columns={col_i: fetched_col})\n",
    "                    \n",
    "                    tmp_file['file_idx'] = ticker\n",
    "                    tmp_file['file_name'] = file\n",
    "                    tmp_file['folder_name'] = folder\n",
    "\n",
    "                    core_plus_useful_columns = core_plus_useful_columns.append(tmp_file)\n",
    "                \n",
    "                except:\n",
    "                    unfit_files.append([file, folder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some general statistics concerning: \n",
    "* __`Total files: `__ Total files available from both years.\n",
    "* __`Used files: `__ Total compatible files appended.\n",
    "* __`Unfit files: `__ List of incompatible files.\n",
    "* __`Useful columns: `__ The list of useful columns I will be using from other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 120 | Used files: 117 (97%)\n",
      "Unfit files:  [['22792758.csv', 'csv_data_2023'], ['22792769.csv', 'csv_data_2023'], ['22351450.csv', 'csv_data_2022']]\n",
      "\n",
      " Useful raw columns identified:  ['cartype' 'category' 'category of vehicle' 'direction of travel'\n",
      " 'direction of vehicle' 'eco-friendly' 'ecofriendly' 'electric'\n",
      " 'electric / non-electric vehicle' 'electric or hybrid?' 'electric or not'\n",
      " 'electric vehicle' 'electric_vehicle' 'engine' 'engine type' 'ev' 'fuel'\n",
      " 'fuel type' 'green badge' 'green vehicle' 'hasgreennumberplate'\n",
      " 'is electric' 'is_env_fr' 'is_env_friendly' 'low emissions compliant'\n",
      " 'mode_of_travel' 'not_petrol' 'occupancy of the vehicle' 'owner'\n",
      " 'personal' 'public / private' 'public transport' 'public vehicle'\n",
      " 'public/private' 'purpose' 'time ( in am)'\n",
      " 'transport type (public/private)' 'transportation type'\n",
      " 'type of transportation' 'type of vehicle' 'vehicle occupancy'\n",
      " 'vehicle type' 'vehicle_type' 'zero emission' 'zero emissions']\n",
      "\n",
      " Useful columns combined:  ['is_electric' 'type' 'direction' 'is_eco_friendly' 'fuel_type'\n",
      " 'is_public_vehicle' 'occupancy' 'is_personal_vehicle' 'time']\n"
     ]
    }
   ],
   "source": [
    "total = appended_raw['file_idx'].nunique() \n",
    "processed = core_plus_useful_columns['file_idx'].nunique() \n",
    "print('Total files: ' + str(total) + ' | Used files: {} ({}%)'.format(processed, str(processed*100//total)))\n",
    "print('Unfit files: ', unfit_files)\n",
    "print('\\n Useful raw columns identified: ', column_lookup[column_lookup['column_mod']!='unwanted']['raw_column'].unique())\n",
    "print('\\n Useful columns combined: ', column_lookup['column_mod'].unique()[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, all the columns header have been remapped. \n",
    "\n",
    "Individual operations on each column have to be performed now to bring the contents to a consistent format. This function handled errors and inconsistent format but it has been coded to a point where there are no incompatible dates left, so the try/except if just left in place to demonstrate how this was achieved.\n",
    "\n",
    "The date column cleaning is composed of the following key methods: \n",
    "* __`fix_date(date)`__ - This function is a comprehensive date formatter which I developed iteratively using the `try/except` statement. By exhausting the exceptions I was able to write a condition to handle every possible case.\n",
    "* __`try/except`__ - The try except has no use now but is left as a placeholder to demonstrate how I was able to develop the conditions required for every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed = core_plus_useful_columns.copy()\n",
    "\n",
    "def fix_date(date):\n",
    "    try:\n",
    "        if '-' in date:\n",
    "            date = date.strip()\n",
    "            if len(date)==8:\n",
    "                return pd.to_datetime(date, format = '%d-%m-%y')\n",
    "            elif len(date)==10:\n",
    "                if date.startswith('2022'):\n",
    "                    return pd.to_datetime(date, format = '%Y-%m-%d')\n",
    "                else:\n",
    "                    return pd.to_datetime(date, format = '%d-%m-%Y')\n",
    "            elif len(date)==6:\n",
    "                date = date.split('-', 1)[0] + '-10-2022'\n",
    "                return fix_date(date)\n",
    "        elif len(date)==18:\n",
    "            date = date.split(' ', 1)[0]\n",
    "            return pd.to_datetime(date, format = '%Y-%m-%d')\n",
    "        elif len(date)==24:\n",
    "            date = '2024-10-24'\n",
    "            return pd.to_datetime(date, format = '%Y-%m-%d')\n",
    "        elif '/' in date:\n",
    "            if len(date)==12:\n",
    "                date = date.strip()\n",
    "                return fix_date(date)\n",
    "            elif date.endswith('/22'):\n",
    "                return pd.to_datetime(date, format = '%d/%m/%y')\n",
    "            elif date.endswith('2023'):\n",
    "                return pd.to_datetime(date, format = '%d/%m/%Y')\n",
    "            elif date.startswith('2022'):\n",
    "                return pd.to_datetime(date, format = '%Y/%m/%d')\n",
    "            else:\n",
    "                return pd.to_datetime(date, format = '%d/%m/%Y')\n",
    "        elif '-' in date and (date.count(' ')==1):\n",
    "            temp = date.split(' ')[0]\n",
    "            return pd.to_datetime(date, format = '%d-%m-%Y')\n",
    "        elif '.' in date:\n",
    "            return pd.to_datetime(date, format = '%d.%m.%Y')\n",
    "\n",
    "    # placeholder as described in markdown\n",
    "    except:\n",
    "        print('-{}-'.format(date))\n",
    "\n",
    "df_unprocessed['date'] = df_unprocessed['date'].apply(fix_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the wide range of time formats time formats I have done the following: \n",
    "* __`str.replace('.', ':')`__ - Replace all instances of '.' with ':'.\n",
    "* __`str.lower, str.strip`__ - This results in the whole string lowercased with all whitespaces removed.\n",
    "* __`~str.contains('pm')`__ - The cells that contain the string 'pm' will be dropped. These times are outside the scope of the experiment.\n",
    "* __`str.split()`__ - Cells containing 'am' or multiple ':' have been split according to some conditions in order to keep only the useful part of each time.\n",
    "* __`append chr and rstrip()`__ - By attaching a '0' to the left of the time string and slicing 5 characters from the right I deal with the times before 10am and have fewer integers i.e. 8:00, 9:00.\n",
    "* __`fix_time(time)`__ - This function is very important to ensure the time intervals are binned correctly. By taking the minutes part of the time, performing floor division '//' by 5 and multiplying the result by 5 I get the time of the starting 5 minute interval the observation was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/68v3chjn201dq1czqxvs4qh00000gn/T/ipykernel_76623/3754043209.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  time_fix_df['time'] = time_fix_df['time'].str.replace('.', ':')\n"
     ]
    }
   ],
   "source": [
    "time_fix_df = df_unprocessed.copy()\n",
    "\n",
    "time_fix_df['time'] = time_fix_df['time'].str.replace('.', ':')\n",
    "\n",
    "time_fix_df['time'] = time_fix_df['time'].str.lower()\n",
    "time_fix_df['time'] = time_fix_df['time'].str.strip()\n",
    "\n",
    "time_fix_df = time_fix_df[~time_fix_df['time'].str.contains('pm', na=False)]\n",
    "time_fix_df['time'] = time_fix_df['time'].apply(lambda x: x.split('am')[0] if 'am' in str(x) else x)\n",
    "\n",
    "time_fix_df['time'] = time_fix_df['time'].apply(lambda x: x.rsplit(':', 1)[0] if str(x).count(':')==2 else x)\n",
    "\n",
    "time_fix_df['time'] = '0' + time_fix_df['time']\n",
    "time_fix_df['time'] = time_fix_df['time'].str.strip()\n",
    "time_fix_df['time'] = time_fix_df['time'].str[-5:]\n",
    "\n",
    "def fix_time(time):\n",
    "    minutes = int(time.split(':')[1])\n",
    "    minutes = minutes//5*5\n",
    "    return time[:2] + ':' + ('0' + str(minutes))[-2:]\n",
    "\n",
    "time_fix_df['time'] = time_fix_df['time'].apply(fix_time)\n",
    "\n",
    "sample_times = time_fix_df['time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell deals with direction and types inconsistencies.\n",
    "\n",
    "Here I introduce the dictionary lookup for a robust way to replace column inconsistencies. It is composed of two parts:\n",
    "* __`type_lookup`__ - This is a dictionary which has the corrected column values as keys and the possible occurences as items. It has been created by taking the values returned by clean_df['type'].unique() and assigning them to the items of their correct meaning or key.\n",
    "* __`fix_type(v_type)`__ - This function, iterates over the dictionary created for every cell if the value is not already in the predefined format and exists in the items of a given key, it is assigned the current item's key. Cells which have random values not included in the scope will be assigned 'dump' to be dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_fix_df = time_fix_df.copy()\n",
    "\n",
    "direction_fix_df['direction'] = direction_fix_df['direction'].str.lower()\n",
    "direction_fix_df['direction'] = direction_fix_df['direction'].str.strip()\n",
    "direction_fix_df['direction'] = direction_fix_df['direction'].str.capitalize()\n",
    "\n",
    "type_fix_df = direction_fix_df.copy()\n",
    "\n",
    "type_lookup = {'scooter': ['s', 'scooters', 'escooter'], 'bicycle': ['bike', 'bi', 'electric bike'], 'motorbike': ['motorcycle', 'moterbike', 'motor', 'm', 'motor bike', 'moto'], \n",
    "                'car': ['c', 'electric car'], 'taxi': ['t'], 'van': ['v'], 'lorry': ['truck', 'l', 'mini truck'], 'bus': ['bu', 'double decker bus', 'single decker bus', 'u2'], \n",
    "                'dump': ['authorised vehicle', 'other', 'a.v', 'tractor', 'pedestrian']}\n",
    "\n",
    "type_fix_df['type'] = type_fix_df['type'].str.lower()\n",
    "type_fix_df['type'] = type_fix_df['type'].str.strip()\n",
    "\n",
    "def fix_type(v_type):\n",
    "    if v_type not in ['car', 'scooter', 'van', 'bus', 'bicycle', 'lorry', 'taxi', 'motorbike']:\n",
    "        for i, (k, v) in enumerate(type_lookup.items()):\n",
    "            if v_type in v:\n",
    "                return k\n",
    "        # if no match return dump\n",
    "        return 'dump'\n",
    "    # else already in predefined format\n",
    "    else:\n",
    "        return v_type\n",
    "\n",
    "type_fix_df['type'] = type_fix_df['type'].apply(fix_type)\n",
    "type_fix_df = type_fix_df[type_fix_df['type'] != 'dump']\n",
    "type_fix_df['type'] = type_fix_df['type'].str.capitalize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with occupancy has a few `rules/assumptions` to ammend entries with faulty values.\n",
    "\n",
    "__`ASSUMPTIONS: `__ \n",
    "* __`Buses`__ - For buses, all values have to be percentages so any value over 1 is divided by 100.\n",
    "* __`Vans`__ - Vans were supposed to be absolute headcount however some groups decided to use percentage, so a safe assumption was made to set any vans with occupancy over 10 people to be a percentage and multiplied by a typical van size of 10 people. In other words, floor division of 10.\n",
    "* __`Car/Taxi/Lorry`__ - Cars, taxis and lorry assumptions was setting occupancy over 5 people to be a percentage and multiplied by a typical size of 5 people. In other words floor division by 20.\n",
    "* __`Bicycle`__ - Here I am asuming some groups did the same or by accident recorded a higher than realistic number. So I am setting any values higher than 2 to a maximum of 1. I will allow observations of 2 as some parents tow their babies or for cases of tandem bicycles.\n",
    "* __`NULL occupancy`__ - There were some cases of occupancy not having been filled out `(for example in 22792775.csv - 2023 files)` we cannot infer why these exist so the rows containing these cases will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_fix_df = type_fix_df.copy()\n",
    "\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].str.strip()\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].str.lower()\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].replace({'medium': '0.5', 'half-full': '0.5', 'empty': '0'})\n",
    "\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].apply(lambda x: x.split('%')[0] if '%' in str(x) else x)\n",
    "\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].mask(occupancy_fix_df['type'].isin(['Bus']) & (occupancy_fix_df['occupancy'].astype(float) > 1), occupancy_fix_df['occupancy'].astype(float)/100)\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].mask(occupancy_fix_df['type'].isin(['Van']) & (occupancy_fix_df['occupancy'].astype(float) > 10), occupancy_fix_df['occupancy'].astype(float)//10)\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].mask(occupancy_fix_df['type'].isin(['Lorry', 'Car', 'Taxi']) & (occupancy_fix_df['occupancy'].astype(float) > 5), occupancy_fix_df['occupancy'].astype(float)//20)\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].mask(occupancy_fix_df['type'].isin(['Bicycle']) & (occupancy_fix_df['occupancy'].astype(float) > 2), 1)\n",
    "\n",
    "occupancy_fix_df['occupancy'] = occupancy_fix_df['occupancy'].astype('float64')\n",
    "occupancy_fix_df = occupancy_fix_df[~occupancy_fix_df['occupancy'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaning of the core columns of the spec release has now been concluded and I can now proceed to work on the additional columns I have selected to help in my analysis question.\n",
    "\n",
    "__`ASSUMPTIONS: `__ \n",
    "* If a vehicle is not eco-friendly cannot be electric, so 'is_electric' in these cases will be set to zero. It is assumed that in order for a group to have identified eco-friendly vehicles they would have a badge or identifier of some sort which are exclusively infer they use electric power. For these cases if the eco-friendly column is true however NOT for the case of Bicycles. This is because if they have not already been flagged as electric as we cannot be sure if in these cases they are electric are or not. Bicycles are most of the time but it is not reasonable to make this assumption since their non-electric counterparts will still be eco-friendly.\n",
    "* For the case of scooters which follow the same logic being eco-friendly regardless of power type. Since every approach leading to the university has steep inclines and rolling hills, I am assuming that all scooters are electric powered as it would require super human strength to push one-legged up ~150 meters elevation gain reaching 12% gradient in some cases (https://climbfinder.com/en/climbs/bathwick-hill-bathwick#:~:text=Bathwick%20Hill%20from%20Bathwick%20is,179%20meters%20above%20sea%20level). Even if this is possible by some extremely athletic individual it would also be extremely reckless so this is assumed an extraordinary case. \n",
    "\n",
    "The additional columns are different between groups but have been renamed in my initial appending. So naturally they require a good amount of processing before they can be used. It should be noted that the columns are only applicable to the groups which have used them so in any other case the column will be None to ensure we dont get faulty counts.\n",
    "The grouped columns I will be working with are:\n",
    "* __`is_eco_friendly`__ - Is the vehicle eco-friendly? (True/False). This column is used to mask values in 'is_electric' column. \n",
    "* __`is_electric`__ - Is the vehicle electric powered? (True/False). \n",
    "* __`is_public_vehicle`__ - Is it a public use vehicle? (True/False).\n",
    "* __`is_personal_vehicle`__ - Is it a personal use vehicle? (True/False). Adds to 'is_public_vehicle' and is dropped afterwards.\n",
    "* __`fuel_type`__ - How is the vehicle powered? (Zero Emissions Vehicle / Internal Combustion Engine).\n",
    "\n",
    "* __`fix_column(value)`__ - Each column is fixed by using the dicionary function I created for fix_type. This function iterates over the lookup dictionary created for every case if the value exists in the items of a given key, it is assigned the current item's key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_columns_clean = occupancy_fix_df.copy()\n",
    "core_columns = ['date', 'time', 'direction', 'type', 'occupancy', 'file_name', 'file_idx']\n",
    "core_columns_clean[core_columns]\n",
    "\n",
    "\n",
    "########## 'is_electric' additional column fix\n",
    "ev_lookup = {1: ['yes', 'y', 'ev', '1', 'true', 'electric', '+'], 0: ['no', 'n', 'non ev', '0', 'false', 'conventional', '-']}\n",
    "\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].str.strip()\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].str.lower()\n",
    "\n",
    "def fix_ev(value):\n",
    "    for i, (k, v) in enumerate(ev_lookup.items()):\n",
    "        if value in v:\n",
    "            return k\n",
    "\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].apply(fix_ev)\n",
    "\n",
    "\n",
    "########## 'fuel_type' additional column fix\n",
    "fuel_type_lookup = {'ICE': ['ice', 'conventional', 'combustible', 'combustion', 'gasoline', 'gas'], 'ZEV': ['zev', 'clean technology', 'hybrid', 'electric','electrics']}\n",
    "\n",
    "core_columns_clean['fuel_type'] = core_columns_clean['fuel_type'].str.strip()\n",
    "core_columns_clean['fuel_type'] = core_columns_clean['fuel_type'].str.lower()\n",
    "\n",
    "def fix_fuel_type(value):\n",
    "    for i, (k, v) in enumerate(fuel_type_lookup.items()):\n",
    "        if value in v:\n",
    "            return k\n",
    "\n",
    "core_columns_clean['fuel_type'] = core_columns_clean['fuel_type'].apply(fix_fuel_type)\n",
    "\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].mask(core_columns_clean['fuel_type']=='ZEV', 1)\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].mask(core_columns_clean['fuel_type']=='ICE', 0)\n",
    "core_columns_clean.drop(columns=['fuel_type'], inplace=True)\n",
    "\n",
    "\n",
    "########## 'is_eco_friendly' additional column fix\n",
    "eco_friendly_lookup = {1: ['yes', '1', 'y'], 0: [ 'no', '0', 'n']}\n",
    "\n",
    "core_columns_clean['is_eco_friendly'] = core_columns_clean['is_eco_friendly'].str.strip()\n",
    "core_columns_clean['is_eco_friendly'] = core_columns_clean['is_eco_friendly'].str.lower()\n",
    "\n",
    "def fix_eco_friendly(value):\n",
    "    for i, (k, v) in enumerate(eco_friendly_lookup.items()):\n",
    "        if value in v:\n",
    "            return k\n",
    "\n",
    "core_columns_clean['is_eco_friendly'] = core_columns_clean['is_eco_friendly'].apply(fix_eco_friendly)\n",
    "core_columns_clean['is_eco_friendly'] = core_columns_clean['is_eco_friendly'].mask(core_columns_clean['is_electric']==1, 1)\n",
    "core_columns_clean['is_eco_friendly'] = core_columns_clean['is_eco_friendly'].mask(core_columns_clean['is_electric']==0, 0)\n",
    "\n",
    "\n",
    "# If a vehicle is not eco friendly it cannot be an electric car, so 'is_electric' in these cases to zero EXCEPT Bicycles\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].mask(core_columns_clean['is_eco_friendly']==0, 0)\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].mask((core_columns_clean['is_eco_friendly']==1) & (core_columns_clean['type'] != 'Bicycle'), 1)\n",
    "core_columns_clean.drop(columns=['is_eco_friendly'], inplace=True)\n",
    "\n",
    "# According to my assumptions in the previous markdown, any scooters will be considered electric\n",
    "core_columns_clean['is_electric'] = core_columns_clean['is_electric'].mask(core_columns_clean['type'] == 'Scooter', 1)\n",
    "\n",
    "\n",
    "########## 'is_public_vehicle' additional column fix\n",
    "pub_vehicle_lookup = {1: ['yes', '1.0', 'rented', 'public'], 0: ['no', '0.0', 'private']}\n",
    "\n",
    "core_columns_clean['is_public_vehicle'] = core_columns_clean['is_public_vehicle'].str.strip()\n",
    "core_columns_clean['is_public_vehicle'] = core_columns_clean['is_public_vehicle'].str.lower()\n",
    "\n",
    "def fix_public_vehicles(value): \n",
    "    for i, (k, v) in enumerate(pub_vehicle_lookup.items()):\n",
    "        if value in v:\n",
    "            return k\n",
    "\n",
    "core_columns_clean['is_public_vehicle'] = core_columns_clean['is_public_vehicle'].apply(fix_public_vehicles)\n",
    "\n",
    "\n",
    "########## 'is_personal_vehicle' additional column addition to 'is_public_vehicle'\n",
    "core_columns_clean['is_personal_vehicle'] = core_columns_clean['is_personal_vehicle'].replace({'True': 1, 'False': 0})\n",
    "core_columns_clean['is_public_vehicle'] = core_columns_clean['is_public_vehicle'].mask(core_columns_clean['is_personal_vehicle']==0, 1)\n",
    "core_columns_clean['is_public_vehicle'] = core_columns_clean['is_public_vehicle'].mask(core_columns_clean['is_personal_vehicle']==1, 0)\n",
    "core_columns_clean.drop(columns=['is_personal_vehicle'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the cleaning of all the entries. Below is a preview of the clean entries together with some general statistics/info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total files: 120    |   Post processing unique files used: 115 (95.8%)\n",
      "Total rows:  12953  |   Rows used:  : 12403 (95.8%)\n",
      "Unfit file names:  ['22792758.csv' '22792769.csv' '22351450.csv' '22351489.csv'\n",
      " '22351505.csv']\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12403 entries, 0 to 139\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   date               12403 non-null  datetime64[ns]\n",
      " 1   time               12403 non-null  object        \n",
      " 2   direction          12403 non-null  object        \n",
      " 3   type               12403 non-null  object        \n",
      " 4   occupancy          12403 non-null  float64       \n",
      " 5   is_public_vehicle  1201 non-null   float64       \n",
      " 6   file_idx           12403 non-null  int64         \n",
      " 7   file_name          12403 non-null  object        \n",
      " 8   folder_name        12403 non-null  object        \n",
      " 9   is_electric        5152 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(5)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>direction</th>\n",
       "      <th>type</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>is_electric</th>\n",
       "      <th>is_public_vehicle</th>\n",
       "      <th>file_name</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>file_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22351457.csv</td>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22351457.csv</td>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22351457.csv</td>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Lorry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22351457.csv</td>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22351457.csv</td>\n",
       "      <td>csv_data_2022</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>08:55</td>\n",
       "      <td>08</td>\n",
       "      <td>55</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22792726.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>08:55</td>\n",
       "      <td>08</td>\n",
       "      <td>55</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22792726.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>08:55</td>\n",
       "      <td>08</td>\n",
       "      <td>55</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22792726.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12401</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>08:55</td>\n",
       "      <td>08</td>\n",
       "      <td>55</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22792726.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12402</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>08:55</td>\n",
       "      <td>08</td>\n",
       "      <td>55</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22792726.csv</td>\n",
       "      <td>csv_data_2023</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12403 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  year month day   time hour minute direction   type  \\\n",
       "0     2022-10-24  2022    10  24  10:20   10     20       Out    Car   \n",
       "1     2022-10-24  2022    10  24  10:20   10     20       Out    Bus   \n",
       "2     2022-10-24  2022    10  24  10:20   10     20       Out    Car   \n",
       "3     2022-10-24  2022    10  24  10:20   10     20       Out  Lorry   \n",
       "4     2022-10-24  2022    10  24  10:20   10     20       Out    Car   \n",
       "...          ...   ...   ...  ..    ...  ...    ...       ...    ...   \n",
       "12398 2023-10-27  2023    10  27  08:55   08     55       Out    Car   \n",
       "12399 2023-10-27  2023    10  27  08:55   08     55       Out    Car   \n",
       "12400 2023-10-27  2023    10  27  08:55   08     55       Out    Bus   \n",
       "12401 2023-10-27  2023    10  27  08:55   08     55       Out    Car   \n",
       "12402 2023-10-27  2023    10  27  08:55   08     55       Out    Car   \n",
       "\n",
       "       occupancy  is_electric  is_public_vehicle     file_name    folder_name  \\\n",
       "0            1.0          NaN                NaN  22351457.csv  csv_data_2022   \n",
       "1            0.1          NaN                NaN  22351457.csv  csv_data_2022   \n",
       "2            1.0          NaN                NaN  22351457.csv  csv_data_2022   \n",
       "3            1.0          NaN                NaN  22351457.csv  csv_data_2022   \n",
       "4            2.0          NaN                NaN  22351457.csv  csv_data_2022   \n",
       "...          ...          ...                ...           ...            ...   \n",
       "12398        1.0          NaN                NaN  22792726.csv  csv_data_2023   \n",
       "12399        1.0          NaN                NaN  22792726.csv  csv_data_2023   \n",
       "12400        0.2          1.0                NaN  22792726.csv  csv_data_2023   \n",
       "12401        1.0          NaN                NaN  22792726.csv  csv_data_2023   \n",
       "12402        1.0          NaN                NaN  22792726.csv  csv_data_2023   \n",
       "\n",
       "       file_idx  \n",
       "0            81  \n",
       "1            81  \n",
       "2            81  \n",
       "3            81  \n",
       "4            81  \n",
       "...         ...  \n",
       "12398        74  \n",
       "12399        74  \n",
       "12400        74  \n",
       "12401        74  \n",
       "12402        74  \n",
       "\n",
       "[12403 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entries_clean = core_columns_clean.copy()\n",
    "\n",
    "processed = all_entries_clean['file_idx'].nunique()\n",
    "unfit_files = appended_raw[~appended_raw['file_idx'].isin(all_entries_clean['file_idx'].unique())]['file_name'].unique()\n",
    "print('\\nTotal files: ' + str(total) + '    |   Post processing unique files used: {} ({}%)'.format(processed, str(round(processed*100/total, 1))))\n",
    "print('Total rows: ', len(appended_raw), ' |   Rows used:  : {} ({}%)'.format(len(all_entries_clean), round(len(all_entries_clean)*100/len(appended_raw), 1)))\n",
    "print('Unfit file names: ', unfit_files)\n",
    "\n",
    "print('\\n')\n",
    "print(all_entries_clean.info())\n",
    "\n",
    "all_entries_clean['year'] = all_entries_clean['date'].dt.strftime('%Y')\n",
    "all_entries_clean['month'] = all_entries_clean['date'].dt.strftime('%m')\n",
    "all_entries_clean['day'] = all_entries_clean['date'].dt.strftime('%d')\n",
    "\n",
    "all_entries_clean['hour'] = all_entries_clean['time'].apply(lambda x: x.split(':')[0])\n",
    "all_entries_clean['minute'] = all_entries_clean['time'].apply(lambda x: x.split(':')[1])\n",
    "\n",
    "all_entries_clean = all_entries_clean[['date', 'year', 'month', 'day', 'time', 'hour', 'minute', 'direction', 'type', 'occupancy', 'is_electric', 'is_public_vehicle', 'file_name', 'folder_name', 'file_idx']]\n",
    "\n",
    "all_entries_clean = all_entries_clean.sort_values(['date', 'hour', 'minute']).reset_index(drop=True)\n",
    "\n",
    "all_entries_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RESEARCH QUESTION / ANALYSIS STEPS\n",
    "\n",
    "\n",
    "__`GOV charging stations grant effect on electric cars`__ <br>\n",
    "In March 2022 the UK government rolled out a plan to install 50,000 electric vehicle chargers at universities, colleges and schools [1]. This grant was announced at a convenient time for the time frame of our data and allows us to compare the percentage of EV traffic between 2022 and 2023. An important note is that EV chargers concern car owners almost exclusively as private electric bicycles and scooters have unique charging cables in most cases which are not carried by users due to weight and size. <br>\n",
    "`Analysis steps:`\n",
    "* First filter the entries to show only electric vehicles and cars.\n",
    "* Due to the imbalance of sample sizes we will be comparing types of electric vehicles observed as a portion of total EV's observed for each year respectively. \n",
    "* For each year I will diplay the total applicable sample (the number of entries that are not NAN in the `is_electric` column) in the center of a donut chart and the percentage and absolute numbers of electric vs non-electric cars on the outer donut portions.\n",
    "* Plotting the donuts next to eachother will allow the reader to easily compare the figures for 2022 and 2023.\n",
    "\n",
    "\n",
    "__`What percentage of UK electric vehicle owners visited the university on a single day?`__ <br>\n",
    "According to the study \"The future is electric: How adopting EVs is good business\" written by Tom Bloor for Open Access Government, there are currently 265,000 EV owners in the UK, which means we can infer the portion of UK EV owners driving into campus by using the ratio of the maximum EV's of a given day to the national total. <br>\n",
    "`Analysis steps:`\n",
    "* A vehicle could be observed driving in an out causing it to be counted twice, so I will start by filtering to only inflowing electric vehicles. This assumes the same car will not drive in, out and then in again.\n",
    "* Scooters and bicycles would not be registered to individuals and wouldn't contribute to the total national figure so these will also be excluded.\n",
    "* For each year I will show the maximum daily figure of inflowing vehicles and represent this as a percentage of the national total.\n",
    "* A intermediate helper visual will be included for the reader to quickly see the percentage increase from 2022 to 2023.\n",
    "\n",
    "\n",
    "__`A look into electric vehicles as a percentage of respective yearly EV total excluding cars`__ <br>\n",
    "A small helper table will be added to show the reader that cars make up 68.9% of all entries and therefore the analysis on one side will focus on the rest of the vehicles separately. Micromobility schemes i.e. `Tier` who use a replacable power unit [2] so they would not make use of public charging points in any case. However, in September 2023 Tier announced the UK Access Scheme [3] which gives a substantial discount of 30% to Students and Professors to user their service which makes it even cheaper than using the bus in many cases. This also was announced conveniently before the start of the semester, therefore, I am expecting to have a noticeable increase in scooter and bicycle traffic in 2023. <br>\n",
    "`Analysis steps:`\n",
    "* Filter vehicle types to show all electric vehicles except cars.\n",
    "* Calculate the percentage of the total yearly EV observations each vehicle represents. Sample sizes are unbalanced so I have to work with percentages.\n",
    "* Plot the 2022 and 2023 figures in a side-by-side barplot and sort in the vehicles in descending order to help the reader quickly understand the chart.\n",
    "\n",
    "\n",
    "__`REFERENCES:`__ \n",
    "* [1] Matt de Prez. 2022. 50,000 EV chargers to be installed at schools, colleges and universities. [Online]. Available from: https://www.fleetnews.co.uk/news/latest-fleet-news/electric-fleet-news/2022/03/30/50-000-ev-chargers-to-be-installed-at-schools-colleges-and-universities\n",
    "* [2] Steve O'Hear. 2020. Tier Mobility, the European e-scooter rentals startup, adds another ~$40M to its Series B. [Online]. Available from: https://techcrunch.com/2020/02/21/tier-series-b-2/ \n",
    "* [3] Department of Communications. 2023. TIER launches shared e-bike and e-scooter service in Bath and Bristol. [Online]. Available from: https://www.bath.ac.uk/announcements/tier-launches-shared-e-bike-and-e-scooter-service-in-bath-and-bristol/\n",
    "* [4] Tom Bloor. 2023. The future is electric: How adopting EVs is good business. [Online]. Available from: https://www.openaccessgovernment.org/future-electric-adopting-evs-good-business-evec/156358/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA EXPLORATION / PRELIMINARY VISUALISATION\n",
    "I will create some preliminary plots using Matplotlib, however, I will use Tableau to create richer charts for my final infographic.\n",
    "\n",
    "There additional boolean columns I creating in the previous section are: \n",
    "* __`is_electric`__ - Indicates whether the vehicle is electric powered or not. Is a boolean value for the applicable sample, and NAN for groups which did not record this information.\n",
    "* __`is_public_vehicle`__ - Indicates whether it is a public vehicle or not. Is a boolean value for the applicable sample, and NAN for groups which did not record this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>direction</th>\n",
       "      <th>type</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>is_public_vehicle</th>\n",
       "      <th>is_electric</th>\n",
       "      <th>file_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>Out</td>\n",
       "      <td>Van</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:45</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:45</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:45</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>10:50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year month day   time hour minute direction type  occupancy  \\\n",
       "0 2023-10-23  2023    10  23  10:30   10     30       Out  Van       0.50   \n",
       "1 2023-10-23  2023    10  23  10:45   10     45       Out  Car       0.20   \n",
       "2 2023-10-23  2023    10  23  10:45   10     45       Out  Bus       0.20   \n",
       "3 2023-10-23  2023    10  23  10:50   10     50       Out  Car       0.20   \n",
       "4 2023-10-23  2023    10  23  10:30   10     30       Out  Car       0.20   \n",
       "5 2023-10-23  2023    10  23  10:30   10     30       Out  Car       0.20   \n",
       "6 2023-10-23  2023    10  23  10:50   10     50       Out  Bus       0.05   \n",
       "7 2023-10-23  2023    10  23  10:50   10     50       Out  Car       0.20   \n",
       "8 2023-10-23  2023    10  23  10:45   10     45       Out  Car       0.20   \n",
       "9 2023-10-23  2023    10  23  10:50   10     50       Out  Car       0.40   \n",
       "\n",
       "   is_public_vehicle  is_electric  file_idx  \n",
       "0                1.0          NaN         1  \n",
       "1                0.0          NaN         1  \n",
       "2                0.0          NaN         1  \n",
       "3                1.0          NaN         1  \n",
       "4                0.0          NaN         1  \n",
       "5                0.0          NaN         1  \n",
       "6                1.0          NaN         1  \n",
       "7                0.0          NaN         1  \n",
       "8                0.0          NaN         1  \n",
       "9                0.0          NaN         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "complete_df = all_entries_clean.copy()\n",
    "complete_df = complete_df[['date', 'year', 'month', 'day', 'time', 'hour', 'minute', 'direction', 'type', 'occupancy', 'is_public_vehicle', 'is_electric', 'file_idx']]\n",
    "complete_df = complete_df.sort_values('file_idx').reset_index(drop=True)\n",
    "\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I am finalizing my dataframe to a good level for me to be able to use it efficiently in Tableau.\n",
    "\n",
    "It is important to acknowledge that in some cases, two or more groups recorded traffic at the same time. To resolve this issue the process is as follows.\n",
    "\n",
    "__`DUPLICATE OBSERVATIONS:`__\n",
    "* Group to the lowest level; date, time, direction, type AND file_idx which in this case is one individual recording traffic in a given direction. This gives us the total vehicle type observations per individual for a given 5-minute interval.\n",
    "* Sort by descending observations at the lowest level again and drop_duplicates keeping only the first entry. \n",
    "\n",
    "In effect, I am keeping the individual who recorded the most vehicles in a given time interval, type and direction.\n",
    "\n",
    "__`ASSUMPTIONS:`__\n",
    "* On average I am assuming that buses have a maximum capacity of 80 people, which I will multiply the occupancy percentage by.\n",
    "* In keeping the observations with most vehicles counted, I am assuming that it is unlikely students imagined vehicles but more likely that they missed some.\n",
    "\n",
    "Finally I am printing some general statistics concerning duplicate observations before and after the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries:  12403 \n",
      "\n",
      "Number of entries for each year:\n",
      "2023    7857\n",
      "2022    4546\n",
      "Name: year, dtype: int64 \n",
      "\n",
      "Number of rows for non-duplicate entries, aggregated to unique time interval and vehicle type:  9501 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>direction</th>\n",
       "      <th>type</th>\n",
       "      <th>file_idx</th>\n",
       "      <th>vehicle_count</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>is_public_vehicle</th>\n",
       "      <th>total_electric</th>\n",
       "      <th>is_electric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>In</td>\n",
       "      <td>Bus</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>In</td>\n",
       "      <td>Car</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>In</td>\n",
       "      <td>Van</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Bus</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Out</td>\n",
       "      <td>Car</td>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year month day   time hour minute direction type  file_idx  \\\n",
       "0 2022-10-24  2022    10  24  10:20   10     20        In  Bus        97   \n",
       "1 2022-10-24  2022    10  24  10:20   10     20        In  Car        97   \n",
       "2 2022-10-24  2022    10  24  10:20   10     20        In  Van        97   \n",
       "3 2022-10-24  2022    10  24  10:20   10     20       Out  Bus        81   \n",
       "4 2022-10-24  2022    10  24  10:20   10     20       Out  Car        81   \n",
       "\n",
       "   vehicle_count  occupancy  is_public_vehicle  total_electric  is_electric  \n",
       "0              2  56.000000                0.0             0.0            0  \n",
       "1              7   1.571429                0.0             2.0            1  \n",
       "2              1   2.000000                0.0             0.0            0  \n",
       "3              2  12.000000                0.0             0.0            0  \n",
       "4             11   1.272727                0.0             0.0            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_intervals_df = complete_df.copy()\n",
    "\n",
    "total_unfiltered = len(group_intervals_df)\n",
    "print('Total entries: ',  total_unfiltered, '\\n')\n",
    "print('Number of entries for each year:')\n",
    "print(group_intervals_df['year'].value_counts(), '\\n')\n",
    "\n",
    "# General aggregation for each direction of travel on a per CSV basis i.e. one students observations. \n",
    "# I am grouping by date, time (5 min interval), direction and type, to return: the sum of vehicle count (total vehicles),\n",
    "# the average occupancy, and the sum of public and electric vehicles individually to get the totals for each case.\n",
    "group_intervals_df['vehicle_count'] = 1\n",
    "group_intervals_df = group_intervals_df.groupby(['date', 'year', 'month', 'day', 'time', 'hour', 'minute', 'direction', 'type', 'file_idx'], as_index=False).aggregate({'vehicle_count': 'sum',\n",
    "                                                                                                                                                                        'occupancy': 'mean',\n",
    "                                                                                                                                                                        'is_public_vehicle': 'sum',\n",
    "                                                                                                                                                                        'is_electric': 'sum'})\n",
    "\n",
    "# Multiply bus percentage occupancy by 80 people which is assumed to be max capacity.\n",
    "max_cap = 80\n",
    "group_intervals_df['occupancy'] = group_intervals_df['occupancy'].mask(group_intervals_df['type'] == 'Bus', group_intervals_df['occupancy'] * max_cap)\n",
    "\n",
    "# Sort the dataframe by date, time, direction, type in increasing order but the vehicle count in decreasing order. Drop duplicate rows with the same time direction and type by keeping the one with the most observations.\n",
    "group_intervals_df = group_intervals_df.sort_values(by=['date', 'time', 'direction', 'type', 'vehicle_count'], ascending=[True, True, True, True, False])\n",
    "total_clashing = group_intervals_df.duplicated(['date', 'time', 'direction', 'type']).count()\n",
    "group_intervals_df = group_intervals_df.drop_duplicates(subset=['date', 'time', 'direction', 'type'], keep='first')\n",
    "\n",
    "print('Number of rows for non-duplicate entries, aggregated to unique time interval and vehicle type: ',  (total_unfiltered-total_clashing), '\\n')\n",
    "\n",
    "# Due to this aggregation is_electric became the amount of electric vehicles observed in a given interval. \n",
    "# It has been renamed to total electric and is_electric is recreated using the new column.\n",
    "group_intervals_df = group_intervals_df.rename(columns={'is_electric': 'total_electric'})\n",
    "group_intervals_df['is_electric'] = np.where(group_intervals_df['total_electric'] > 0, 1, 0)\n",
    "\n",
    "# This is the final dataframe I will export to a flat file\n",
    "group_intervals_df.to_csv(r'DATA/clean_data_tableau.csv', index=False)\n",
    "\n",
    "group_intervals_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`APPLICABLE SAMPLE: `__ \n",
    "* I would ideally like to work with data concerning electric vehicles, so as a first step I need to filter my total entries to those which have information in the relevant column 'is_electric'.\n",
    "* The applicable sample in this case would be rows who's value in the is_electric column is not NAN. These are the rows of csv's which have explicitly recorded if the vehicle is electric, or if this has been inferred using other columns.\n",
    "\n",
    "__`INSIGHTS: `__ \n",
    "* It is clear that cars predominantly make up the the sample sizes (over 90% for electric vehicles). \n",
    "* The analysis will be split to focus on cars and the rest of the vehicles separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>is_electric</th>\n",
       "      <th>total_vehicles</th>\n",
       "      <th>perc_of_vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>92.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>90.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>64.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>Car</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>56.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>12.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>Van</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>Van</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>Lorry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bus</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>Lorry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>Van</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bus</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>Van</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022</td>\n",
       "      <td>Lorry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>Lorry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year       type  is_electric  total_vehicles  perc_of_vtype\n",
       "5   2022        Car          1.0           686.0          92.33\n",
       "19  2023        Car          1.0           898.0          90.80\n",
       "18  2023        Car          0.0          2017.0          64.48\n",
       "4   2022        Car          0.0          1133.0          56.45\n",
       "2   2022        Bus          0.0           277.0          13.80\n",
       "16  2023        Bus          0.0           383.0          12.24\n",
       "12  2022        Van          0.0           194.0           9.67\n",
       "26  2023        Van          0.0           242.0           7.74\n",
       "0   2022    Bicycle          0.0           147.0           7.32\n",
       "10  2022       Taxi          0.0           140.0           6.98\n",
       "14  2023    Bicycle          0.0           167.0           5.34\n",
       "24  2023       Taxi          0.0           162.0           5.18\n",
       "6   2022      Lorry          0.0            73.0           3.64\n",
       "17  2023        Bus          1.0            32.0           3.24\n",
       "20  2023      Lorry          0.0            88.0           2.81\n",
       "22  2023  Motorbike          0.0            69.0           2.21\n",
       "13  2022        Van          1.0            16.0           2.15\n",
       "8   2022  Motorbike          0.0            43.0           2.14\n",
       "23  2023    Scooter          1.0            21.0           2.12\n",
       "25  2023       Taxi          1.0            18.0           1.82\n",
       "11  2022       Taxi          1.0            13.0           1.75\n",
       "3   2022        Bus          1.0            13.0           1.75\n",
       "9   2022    Scooter          1.0            10.0           1.35\n",
       "15  2023    Bicycle          1.0            10.0           1.01\n",
       "27  2023        Van          1.0             8.0           0.81\n",
       "1   2022    Bicycle          1.0             3.0           0.40\n",
       "7   2022      Lorry          1.0             2.0           0.27\n",
       "21  2023      Lorry          1.0             2.0           0.20\n",
       "28  2022  Motorbike          1.0             0.0           0.00\n",
       "29  2022    Scooter          0.0             0.0           0.00\n",
       "30  2023  Motorbike          1.0             0.0           0.00\n",
       "31  2023    Scooter          0.0             0.0           0.00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The applicable sample dfs in our case are those where the is_electric column is not NAN\n",
    "applicable_sample = group_intervals_df[(~group_intervals_df['is_electric'].isna())]\n",
    "\n",
    "# Grouping by year, type and is_electric to calculate totals and the percentage they represent in the yearly ev observations for each vehicle type\n",
    "vtypes_group_yr = applicable_sample.groupby(['year', 'type', 'is_electric'], as_index=False)['vehicle_count'].agg({'total_vehicles': 'sum'})\n",
    "vtypes_group_yr['perc_of_vtype'] = vtypes_group_yr['total_vehicles'] / vtypes_group_yr.groupby(['year', 'is_electric'])['total_vehicles'].transform('sum')\n",
    "vtypes_group_yr['perc_of_vtype'] = (vtypes_group_yr['perc_of_vtype'] * 100).round(2)\n",
    "\n",
    "# Creating a blank dataframe for all possible year and type combinations to cross join and add empty rows when there were no observations to avoid errors when plotting side by side bar charts\n",
    "cross_df = pd.DataFrame(columns=['year', 'type', 'is_electric'])\n",
    "for year in ['2022', '2023']:\n",
    "    for type in complete_df['type'].unique():\n",
    "        for elec in [0, 1]:\n",
    "            cross_df = pd.concat([cross_df, pd.DataFrame({'year': [year], 'type': [type], 'is_electric': [elec]})], axis=0)\n",
    "cross_df = cross_df.reset_index(drop=True)\n",
    "\n",
    "# This step performs the 'cross' join to fill any cases where there were no EV observations for the given vehicle type and setting them to zero\n",
    "vtypes_group_yr = pd.merge(vtypes_group_yr, cross_df, how='outer')\n",
    "vtypes_group_yr = vtypes_group_yr.fillna(0)\n",
    "\n",
    "vtypes_group_yr.sort_values('perc_of_vtype', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFTS_KERNEL",
   "language": "python",
   "name": "sfts_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
